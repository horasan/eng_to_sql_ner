{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/horasan/eng_to_sql_ner/blob/main/NER_B_2_full_life_cycle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "7a276939",
      "metadata": {
        "id": "7a276939"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import json\n",
        "import networkx as nx\n",
        "from itertools import product\n",
        "#from transformers import RobertaTokenizerFast, RobertaForTokenClassification\n",
        "#from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import os\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "from typing import Dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# read data from google drive\n",
        "drive.mount('/content/drive')\n",
        "FOLDER_PATH = \"NER_for_SQL\"\n",
        "FULL_PATH = \"/content/drive/My Drive/Colab Notebooks/\" + FOLDER_PATH + \"/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXL0TNdYpCAc",
        "outputId": "300a918d-7c17-493c-ae58-82a2a4444e4b"
      },
      "id": "OXL0TNdYpCAc",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "bio_tagged_dataset_file_name   = \"synthetic_queries_300_bio_tagged.txt\"\n",
        "\n",
        "tag2id_with_cust_file_name = \"tag2id_with_cust.json\"\n",
        "id2tag_with_cust_file_name = \"id2tag_with_cust.json\"\n",
        "\n",
        "trained_model_path = FULL_PATH + \"ner-roberta-with-cust\"\n",
        "trained_tokenizer_path = FULL_PATH + \"ner-roberta-with-cust\""
      ],
      "metadata": {
        "id": "GS2ye6iro_N5"
      },
      "id": "GS2ye6iro_N5",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "554f206b",
      "metadata": {
        "id": "554f206b"
      },
      "source": [
        "# utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "b99f320e",
      "metadata": {
        "id": "b99f320e"
      },
      "outputs": [],
      "source": [
        "def predict(text, tokenizer, model, id2tag):\n",
        "    # Tokenize input\n",
        "    tokens = text.split()\n",
        "    encoding = tokenizer(\n",
        "        tokens,\n",
        "        is_split_into_words=True,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "    # Remove offset_mapping before feeding to model\n",
        "    encoding.pop(\"offset_mapping\")\n",
        "\n",
        "    # Run inference\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(**encoding)\n",
        "        predictions = torch.argmax(output.logits, dim=-1)\n",
        "\n",
        "    # Get word-level predictions\n",
        "    word_ids = encoding.word_ids()\n",
        "    results = []\n",
        "    for idx, word_idx in enumerate(word_ids):\n",
        "        if word_idx is not None and (idx == 0 or word_idx != word_ids[idx - 1]):\n",
        "            label_id = predictions[0][idx].item()\n",
        "            #tag = id2tag.get(label_id, \"O\")  # default to \"O\" if not found\n",
        "            results.append((tokens[word_idx], id2tag[label_id]))\n",
        "            #results.append((tokens[word_idx], tag))\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def ner_tuples_to_json(tagged_tokens):\n",
        "    entities = defaultdict(str)\n",
        "    current_entity = None\n",
        "\n",
        "    for token, tag in tagged_tokens:\n",
        "        if tag.startswith(\"B-\"):\n",
        "            current_entity = tag[2:]\n",
        "            entities[current_entity] += token.lstrip(\"▁\").strip() + \" \"\n",
        "        elif tag.startswith(\"I-\") and current_entity:\n",
        "            entities[current_entity] += token.lstrip(\"▁\").strip() + \" \"\n",
        "        else:\n",
        "            current_entity = None  # Reset if it's \"O\" or invalid\n",
        "\n",
        "    # Strip trailing spaces\n",
        "    return {k: v.strip() for k, v in entities.items()}"
      ],
      "metadata": {
        "id": "E19FM30gSaHn"
      },
      "id": "E19FM30gSaHn",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(name):\n",
        "    return name.lower()"
      ],
      "metadata": {
        "id": "qHYI_-LarEa-"
      },
      "id": "qHYI_-LarEa-",
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_schema_config(schema_json_path):\n",
        "    with open(schema_json_path, 'r') as f:\n",
        "        schema = json.load(f)\n",
        "\n",
        "    graph = nx.Graph()\n",
        "    entity_to_tables = {}\n",
        "\n",
        "    # Add tables and columns as nodes and map entities\n",
        "    for table in schema['tables']:\n",
        "        table_name = normalize(table['table_name'])\n",
        "        graph.add_node(table_name)\n",
        "        for col in table.get('columns', []):\n",
        "            col_name = normalize(col['name'])\n",
        "            if 'business_entity' in col:\n",
        "                entity = normalize(col['business_entity'])\n",
        "                entity_to_tables.setdefault(entity, set()).add(table_name)\n",
        "\n",
        "    # Add relationships as edges with FK info as attributes\n",
        "    for rel in schema.get('relationships', []):\n",
        "        from_table = normalize(rel['from_table'])\n",
        "        to_table = normalize(rel['to_table'])\n",
        "        from_col = normalize(rel.get('from_column', ''))\n",
        "        to_col = normalize(rel.get('to_column', ''))\n",
        "        graph.add_edge(from_table, to_table, from_column=from_col, to_column=to_col)\n",
        "\n",
        "    return entity_to_tables, graph"
      ],
      "metadata": {
        "id": "PjRktieOrJa5"
      },
      "id": "PjRktieOrJa5",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SmartTableResolver_old:\n",
        "    def __init__(self, entity_to_tables, graph, entity_preference=None):\n",
        "        self.entity_to_tables = entity_to_tables\n",
        "        self.graph = graph\n",
        "        self.entity_preference = entity_preference or {}\n",
        "\n",
        "    def combo_score(self, combo, ner_labels):\n",
        "        score = 0\n",
        "        for ent, tbl in zip(ner_labels, combo):\n",
        "            prefs = self.entity_preference.get(ent, [])\n",
        "            try:\n",
        "                score += prefs.index(tbl)\n",
        "            except ValueError:\n",
        "                score += 100\n",
        "        return score\n",
        "\n",
        "    def resolve(self, ner_labels):\n",
        "        ner_labels = [normalize(l) for l in ner_labels]\n",
        "        print(f\"NER labels normalized: {ner_labels}\")\n",
        "\n",
        "        candidates_per_entity = []\n",
        "        for ent in ner_labels:\n",
        "            if ent not in self.entity_to_tables:\n",
        "                print(f\"Unknown entity: {ent}\")\n",
        "                return []\n",
        "            print(f\"Entity '{ent}' candidates: {self.entity_to_tables[ent]}\")\n",
        "            candidates_per_entity.append(list(self.entity_to_tables[ent]))\n",
        "\n",
        "        best_solution = None\n",
        "        best_combo = None\n",
        "        best_score = None\n",
        "        best_relationships = None\n",
        "\n",
        "        for combo in product(*candidates_per_entity):\n",
        "            terminals = set(combo)\n",
        "            disconnected = False\n",
        "            nodes_in_paths = set()\n",
        "            rel_columns = set()\n",
        "\n",
        "            terminals_list = list(terminals)\n",
        "            for i in range(len(terminals_list)):\n",
        "                for j in range(i + 1, len(terminals_list)):\n",
        "                    src = terminals_list[i]\n",
        "                    tgt = terminals_list[j]\n",
        "                    try:\n",
        "                        path = nx.shortest_path(self.graph, src, tgt)\n",
        "                        for u, v in zip(path[:-1], path[1:]):\n",
        "                            edge_data = self.graph.get_edge_data(u, v, default={})\n",
        "                            from_col = edge_data.get('from_column', '')\n",
        "                            to_col = edge_data.get('to_column', '')\n",
        "                            rel_columns.add( (u, from_col, v, to_col) )\n",
        "                        nodes_in_paths.update(path)\n",
        "                    except nx.NetworkXNoPath:\n",
        "                        disconnected = True\n",
        "                        break\n",
        "                if disconnected:\n",
        "                    break\n",
        "\n",
        "            if disconnected:\n",
        "                continue\n",
        "\n",
        "            solution_nodes = nodes_in_paths.union(terminals)\n",
        "            score = self.combo_score(combo, ner_labels)\n",
        "            #print(f\"Testing combo: {combo}\")\n",
        "            #print(f\"Nodes in paths for combo: {solution_nodes}\")\n",
        "            #print(f\"Combo score: {score}\")\n",
        "\n",
        "            if best_solution is None or score < best_score:\n",
        "                best_solution = solution_nodes\n",
        "                best_combo = combo\n",
        "                best_score = score\n",
        "                best_relationships = rel_columns\n",
        "                #print(f\"New best solution: {best_solution} with score {best_score}\")\n",
        "\n",
        "        if best_solution is None:\n",
        "            print(\"No valid solution found\")\n",
        "            return []\n",
        "\n",
        "        relationships_list = [\n",
        "            {\n",
        "                \"from_table\": from_tbl,\n",
        "                \"from_column\": from_col,\n",
        "                \"to_table\": to_tbl,\n",
        "                \"to_column\": to_col\n",
        "            }\n",
        "            for (from_tbl, from_col, to_tbl, to_col) in best_relationships\n",
        "        ]\n",
        "\n",
        "        #print(f\"Best combo chosen: {best_combo}\")\n",
        "        return {\n",
        "            \"tables\": sorted(best_solution),\n",
        "            \"relationships\": relationships_list\n",
        "        }"
      ],
      "metadata": {
        "id": "ZRawxOetrMIL"
      },
      "id": "ZRawxOetrMIL",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sql_with_joins_using_where(resolved_result):\n",
        "    tables = resolved_result[\"tables\"]\n",
        "    relationships = resolved_result[\"relationships\"]\n",
        "\n",
        "    # Lowercase table names for SQL consistency\n",
        "    formatted_tables = [t.lower() for t in tables]\n",
        "    select_clause = \"SELECT *\"\n",
        "    from_clause = f\"FROM {', '.join(formatted_tables)}\"\n",
        "    where_clauses = []\n",
        "\n",
        "    for rel in relationships:\n",
        "        left = f\"{rel['from_table'].lower()}.{rel['from_column'].lower()}\"\n",
        "        right = f\"{rel['to_table'].lower()}.{rel['to_column'].lower()}\"\n",
        "        where_clauses.append(f\"{left} = {right}\")\n",
        "\n",
        "    where_clause = \"\"\n",
        "    if where_clauses:\n",
        "        where_clause = \"WHERE \" + \" AND \".join(where_clauses)\n",
        "\n",
        "    sql_query = f\"{select_clause}\\n{from_clause}\\n{where_clause}\"\n",
        "    return sql_query\n"
      ],
      "metadata": {
        "id": "2RHhlB8wrRDD"
      },
      "id": "2RHhlB8wrRDD",
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Write to file just for loading function (or modify loader to accept dict)\n",
        "    schema_file = \"NER-B-1_schema_info_trs.json\"\n",
        "\n",
        "    entity_to_tables, graph = load_schema_config(FULL_PATH + schema_file)\n",
        "\n",
        "    # Define preferences: lower index = higher preference for table per entity\n",
        "    entity_preference = {\n",
        "        \"dealer\": [\"TRS.DEAL_MASTER\"],\n",
        "        \"deal_date\": [\"TRS.DEAL_MASTER\"],\n",
        "        \"value_date\": [\"TRS.DEAL_MASTER\", \"TRS.DEAL_DETAIL\"],\n",
        "        \"customer_name\": [\"TRS.CUSTOMER\"]\n",
        "    }\n",
        "\n",
        "    resolver = SmartTableResolver_old(entity_to_tables, graph, entity_preference)\n",
        "\n"
      ],
      "metadata": {
        "id": "7944ue0nrTcw"
      },
      "id": "7944ue0nrTcw",
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_sql_with_entity_filters_and_values(result: Dict, schema: Dict, business_entity_values: Dict[str, str], put_extracted_values=True) -> str:\n",
        "    tables = result['tables']\n",
        "    relationships = result['relationships']\n",
        "\n",
        "    where_clauses = []\n",
        "\n",
        "    for rel in relationships:\n",
        "        left = f\"{rel['from_table'].lower()}.{rel['from_column'].lower()}\"\n",
        "        right = f\"{rel['to_table'].lower()}.{rel['to_column'].lower()}\"\n",
        "        where_clauses.append(f\"{left} = {right}\")\n",
        "\n",
        "    entity_keys_normalized = {k.strip().lower(): k for k in business_entity_values}\n",
        "\n",
        "    for table_info in schema['tables']:\n",
        "        table = table_info['table_name'].lower()\n",
        "        for col in table_info.get('columns', []):\n",
        "            entity = col.get('business_entity')\n",
        "            if not entity:\n",
        "                continue\n",
        "            norm_entity = entity.strip().lower()\n",
        "            if norm_entity in entity_keys_normalized:\n",
        "                original_key = entity_keys_normalized[norm_entity]\n",
        "                value = business_entity_values[original_key]\n",
        "                val_repr = f\"'{value}'\" if put_extracted_values else f\"@{entity}\"\n",
        "                where_clauses.append(f\"{table}.{col['name'].lower()} = {val_repr}\")\n",
        "\n",
        "    sql = f\"SELECT *\\nFROM {', '.join(tables)}\\nWHERE\\n    \" + \"\\n    AND \".join(where_clauses)\n",
        "    return sql"
      ],
      "metadata": {
        "id": "xpe_LFIDrX7U"
      },
      "id": "xpe_LFIDrX7U",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_valid_relationships(tables_info, full_schema):\n",
        "    valid_tables = set(tables_info['tables'])\n",
        "\n",
        "    # Build a map of table -> set(columns)\n",
        "    table_columns = {\n",
        "        table['table_name'].lower(): {col['name'].lower() for col in table['columns']}\n",
        "        for table in full_schema['tables']\n",
        "    }\n",
        "\n",
        "    valid_rels = []\n",
        "    for rel in full_schema['relationships']:\n",
        "        ft, fc = rel['from_table'].lower(), rel['from_column'].lower()\n",
        "        tt, tc = rel['to_table'].lower(), rel['to_column'].lower()\n",
        "\n",
        "        if ft in valid_tables and tt in valid_tables:\n",
        "            if fc in table_columns.get(ft, set()) and tc in table_columns.get(tt, set()):\n",
        "                valid_rels.append(rel)\n",
        "\n",
        "    return {\n",
        "        \"tables\": tables_info['tables'],\n",
        "        \"relationships\": valid_rels\n",
        "    }\n"
      ],
      "metadata": {
        "id": "uyOarpG2rcxp"
      },
      "id": "uyOarpG2rcxp",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "162b37fe",
      "metadata": {
        "id": "162b37fe"
      },
      "source": [
        "# Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "7c9c2bed",
      "metadata": {
        "id": "7c9c2bed"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaTokenizerFast, RobertaForTokenClassification\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\", add_prefix_space=True)\n",
        "model = AutoModelForTokenClassification.from_pretrained(trained_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cd5f393",
      "metadata": {
        "id": "9cd5f393"
      },
      "source": [
        "## Log saved id-tag files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "b6220ee2",
      "metadata": {
        "id": "b6220ee2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "# just to be sure type is integer\n",
        "with open(FULL_PATH + id2tag_with_cust_file_name, \"r\") as f:\n",
        "    id2tag = {int(k): v for k, v in json.load(f).items()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32a0e9d3",
      "metadata": {
        "id": "32a0e9d3"
      },
      "source": [
        "## Capture the business entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "e824caf1",
      "metadata": {
        "id": "e824caf1"
      },
      "outputs": [],
      "source": [
        "text = \"Get MM trades for ABC BANK with status approved and value date is tomorrow and amount is 3000 and cur is EUR\"\n",
        "result = predict(text, tokenizer, model, id2tag)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_json = ner_tuples_to_json(result)\n",
        "print(result_json)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODc2sMD4SDnb",
        "outputId": "366da1a1-615b-437b-f740-e8ad7738dfcb"
      },
      "id": "ODc2sMD4SDnb",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'DEAL_TYPE': 'MM', 'CUSTOMER_NAME': 'ABC BANK', 'STATUS': 'approved', 'VALUE_DATE': 'tomorrow', 'AMOUNT': '3000', 'CURRENCY': 'EUR'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate SQL"
      ],
      "metadata": {
        "id": "OjoeyJFnq3Az"
      },
      "id": "OjoeyJFnq3Az"
    },
    {
      "cell_type": "code",
      "source": [
        "captured_business_entity_values = result_json\n",
        "\n",
        "# get keys from JSON\n",
        "#ner_labels_from_captured_business_entity_values = [\"DEAL_TYPE\", \"CUSTOMER_NAME\", \"STATUS\", \"VALUE_DATE\", \"AMOUNT\", \"CURRENCY\"]\n",
        "ner_labels_from_captured_business_entity_values = captured_business_entity_values.keys()\n",
        "ner_labels_from_captured_business_entity_values = [l.upper() for l in ner_labels_from_captured_business_entity_values]\n",
        "print(ner_labels_from_captured_business_entity_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFK-PclcSYYH",
        "outputId": "675cd9a5-fd04-4b66-d396-ba9577274a33"
      },
      "id": "aFK-PclcSYYH",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DEAL_TYPE', 'CUSTOMER_NAME', 'STATUS', 'VALUE_DATE', 'AMOUNT', 'CURRENCY']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get possible tables."
      ],
      "metadata": {
        "id": "wFhxSsSItGN-"
      },
      "id": "wFhxSsSItGN-"
    },
    {
      "cell_type": "code",
      "source": [
        "tables = resolver.resolve(ner_labels_from_captured_business_entity_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnHrbMy5tE09",
        "outputId": "a1f23aa2-3a57-45ad-cef9-a4c0a31bd5a8"
      },
      "id": "jnHrbMy5tE09",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NER labels normalized: ['deal_type', 'customer_name', 'status', 'value_date', 'amount', 'currency']\n",
            "Entity 'deal_type' candidates: {'trs.deal_master'}\n",
            "Entity 'customer_name' candidates: {'cus.customer'}\n",
            "Entity 'status' candidates: {'trs.deal_master'}\n",
            "Entity 'value_date' candidates: {'trs.deal_master', 'trs.deal_detail'}\n",
            "Entity 'amount' candidates: {'trs.deal_detail'}\n",
            "Entity 'currency' candidates: {'trs.deal_detail'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load schema data"
      ],
      "metadata": {
        "id": "pGFbOCTftMZx"
      },
      "id": "pGFbOCTftMZx"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(FULL_PATH + schema_file, 'r') as f:\n",
        "        trs_schema = json.load(f)"
      ],
      "metadata": {
        "id": "8g-kjoDNtLUE"
      },
      "id": "8g-kjoDNtLUE",
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean unnecessary tables\n",
        "cleaned_tables = filter_valid_relationships(tables, trs_schema)\n",
        "print(cleaned_tables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkiqRt9FtPjn",
        "outputId": "84bc8834-acb4-4798-89c6-a1ffba8bc739"
      },
      "id": "FkiqRt9FtPjn",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tables': ['cus.customer', 'trs.deal_detail', 'trs.deal_master'], 'relationships': [{'from_table': 'TRS.DEAL_MASTER', 'from_column': 'CUSTOMEROID', 'to_table': 'CUS.CUSTOMER', 'to_column': 'OID'}, {'from_table': 'TRS.DEAL_DETAIL', 'from_column': 'DEALMASTEROID', 'to_table': 'TRS.DEAL_MASTER', 'to_column': 'OID'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print only the related tables."
      ],
      "metadata": {
        "id": "g0qtcsaPte92"
      },
      "id": "g0qtcsaPte92"
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_sql_with_joins_using_where(cleaned_tables))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_fST35-tbwG",
        "outputId": "7bfa9a61-dfc0-458f-fe95-bd2202a66284"
      },
      "id": "B_fST35-tbwG",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT *\n",
            "FROM cus.customer, trs.deal_detail, trs.deal_master\n",
            "WHERE trs.deal_master.customeroid = cus.customer.oid AND trs.deal_detail.dealmasteroid = trs.deal_master.oid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print SQL with parameters"
      ],
      "metadata": {
        "id": "aapjdsugtidg"
      },
      "id": "aapjdsugtidg"
    },
    {
      "cell_type": "code",
      "source": [
        "sql = generate_sql_with_entity_filters_and_values(cleaned_tables, trs_schema, captured_business_entity_values, put_extracted_values=True)\n",
        "print(sql)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZNkzkwvtnlX",
        "outputId": "5afe76bc-84a4-43ca-ef06-13935b639abb"
      },
      "id": "HZNkzkwvtnlX",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELECT *\n",
            "FROM cus.customer, trs.deal_detail, trs.deal_master\n",
            "WHERE\n",
            "    trs.deal_master.customeroid = cus.customer.oid\n",
            "    AND trs.deal_detail.dealmasteroid = trs.deal_master.oid\n",
            "    AND trs.deal_master.valdate = 'tomorrow'\n",
            "    AND trs.deal_master.dealtp = 'MM'\n",
            "    AND trs.deal_master.appstatus = 'approved'\n",
            "    AND trs.deal_detail.curr = 'EUR'\n",
            "    AND trs.deal_detail.valdate = 'tomorrow'\n",
            "    AND trs.deal_detail.amt = '3000'\n",
            "    AND cus.customer.name = 'ABC BANK'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "hf_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}