{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/horasan/eng_to_sql_ner/blob/main/NER_A_2_1_syntetic_data_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a41ac90",
      "metadata": {
        "id": "6a41ac90"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import itertools\n",
        "import random\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# read data from google drive\n",
        "drive.mount('/content/drive')\n",
        "FOLDER_PATH = \"NER_for_SQL\"\n",
        "FULL_PATH = \"/content/drive/My Drive/Colab Notebooks/\" + FOLDER_PATH + \"/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYr5CpF176xg",
        "outputId": "732b22a7-8811-40ce-be2c-c193cbdc355b"
      },
      "id": "gYr5CpF176xg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "002bd165",
      "metadata": {
        "id": "002bd165"
      },
      "source": [
        "# utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf926a14",
      "metadata": {
        "id": "bf926a14"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import re\n",
        "\n",
        "def generate_synthetic_queries(queries, num_samples_per_query=10):\n",
        "    synthetic_data = []\n",
        "\n",
        "    for query_key, query_info in queries.items():\n",
        "        templates = query_info[\"templates\"]\n",
        "        params = query_info[\"params\"]\n",
        "\n",
        "        for _ in range(num_samples_per_query):\n",
        "            template = random.choice(templates)\n",
        "            chosen_params = {\n",
        "                param: random.choice(values)\n",
        "                for param, values in params.items()\n",
        "            }\n",
        "\n",
        "            text = template\n",
        "            entity_spans = []\n",
        "\n",
        "            # Replace placeholders one by one, tracking offsets carefully\n",
        "            def replace_and_track(match):\n",
        "                placeholder = match.group(0)\n",
        "                param_name = placeholder.strip(\"{}\")\n",
        "                value = chosen_params[param_name]\n",
        "                start = match.start()\n",
        "                end = start + len(value)\n",
        "                entity_spans.append((start, end, param_name))\n",
        "                return value\n",
        "\n",
        "            # Use regex to substitute placeholders and track entity positions\n",
        "            pattern = re.compile(r\"\\{(\\w+)\\}\")\n",
        "            output = []\n",
        "            last_idx = 0\n",
        "            for match in pattern.finditer(template):\n",
        "                output.append(template[last_idx:match.start()])\n",
        "                param_name = match.group(1)\n",
        "                value = chosen_params[param_name]\n",
        "                current_start = len(\"\".join(output))\n",
        "                current_end = current_start + len(value)\n",
        "                entity_spans.append((current_start, current_end, param_name))\n",
        "                output.append(value)\n",
        "                last_idx = match.end()\n",
        "            output.append(template[last_idx:])\n",
        "            text = \"\".join(output)\n",
        "\n",
        "            # Sort entity spans by start index to ensure natural sentence order\n",
        "            entity_spans.sort(key=lambda x: x[0])\n",
        "\n",
        "            synthetic_data.append({\n",
        "                \"text\": text,\n",
        "                \"entities\": entity_spans,\n",
        "                \"query_type\": query_key\n",
        "            })\n",
        "\n",
        "    return synthetic_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c011e22",
      "metadata": {
        "id": "6c011e22"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def tokenize_with_char_spans(text):\n",
        "    \"\"\"Tokenize and get (token, start_char, end_char) for each token.\"\"\"\n",
        "    tokens = []\n",
        "    spans = []\n",
        "    for match in re.finditer(r'\\S+', text):\n",
        "        tokens.append(match.group())\n",
        "        spans.append((match.start(), match.end()))\n",
        "    return tokens, spans\n",
        "\n",
        "def convert_to_bio_tags(samples):\n",
        "    \"\"\"Convert text and entity spans to token-level BIO tags.\"\"\"\n",
        "    bio_tagged = []\n",
        "\n",
        "    for sample in samples:\n",
        "        text = sample[\"text\"]\n",
        "        entities = sample[\"entities\"]\n",
        "        tokens, spans = tokenize_with_char_spans(text)\n",
        "        tags = [\"O\"] * len(tokens)\n",
        "\n",
        "        for ent_start, ent_end, label in entities:\n",
        "            for i, (tok_start, tok_end) in enumerate(spans):\n",
        "                if tok_end <= ent_start:\n",
        "                    continue  # Token is before entity\n",
        "                if tok_start >= ent_end:\n",
        "                    break   # Token is after entity\n",
        "                if ent_start <= tok_start < ent_end:  # Token inside entity\n",
        "                    tags[i] = f\"B-{label}\" if tok_start == ent_start else f\"I-{label}\"\n",
        "\n",
        "        bio_tagged.append({\n",
        "            \"text\": text,\n",
        "            \"tokens\": tokens,\n",
        "            \"tags\": tags\n",
        "        })\n",
        "\n",
        "    return bio_tagged\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70df5c01",
      "metadata": {
        "id": "70df5c01"
      },
      "outputs": [],
      "source": [
        "def save_bio_tagged_data(bio_tagged_data, filename):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        for sample in bio_tagged_data:\n",
        "            for token, tag in zip(sample[\"tokens\"], sample[\"tags\"]):\n",
        "                f.write(f\"{token}\\t{tag}\\n\")\n",
        "            f.write(\"\\n\")  # Blank line between sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f726f212",
      "metadata": {
        "id": "f726f212"
      },
      "source": [
        "# 1) Read syntetic templates (with data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c407b524",
      "metadata": {
        "id": "c407b524"
      },
      "outputs": [],
      "source": [
        "# read syntetic-data-query-templates.json\n",
        "synthetic_data_query_templates = 'syntetic_data_query_templates.json'\n",
        "with open(FULL_PATH + synthetic_data_query_templates, 'r') as f:\n",
        "    queries = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "201b5100",
      "metadata": {
        "id": "201b5100"
      },
      "source": [
        "# 2) Generate syntetic sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b09664d",
      "metadata": {
        "id": "9b09664d"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "synthetic_samples will be a list of dictionaries, each containing:\n",
        "- \"text\": the generated query text\n",
        "- \"entities\": a list of tuples (start, end, entity_type) indicating the spans of entities in the text\n",
        "- \"query_type\": the type of query (e.g., \"query1\", \"query2\", etc.)\n",
        "\"\"\"\n",
        "synthetic_samples = generate_synthetic_queries(queries, num_samples_per_query=300)\n",
        "\n",
        "# save to JSON file\n",
        "synthetic_samples_output_file = \"synthetic_queries_300.json\"\n",
        "with open(FULL_PATH + synthetic_samples_output_file, 'w') as f:\n",
        "    json.dump(synthetic_samples, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f803ee61",
      "metadata": {
        "id": "f803ee61"
      },
      "source": [
        "# 3) Generate BIO tagged data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14e3c068",
      "metadata": {
        "id": "14e3c068"
      },
      "outputs": [],
      "source": [
        "#read samples from JSON file\n",
        "with open(FULL_PATH + synthetic_samples_output_file, 'r') as f:\n",
        "    samples_from_file = json.load(f)\n",
        "\n",
        "bio_tagged_syntetic_data = convert_to_bio_tags(samples_from_file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b95190b6",
      "metadata": {
        "id": "b95190b6"
      },
      "outputs": [],
      "source": [
        "# save bio tagged data to JSON file\n",
        "big_tagged_file_name = \"synthetic_queries_300_bio_tagged.txt\"\n",
        "save_bio_tagged_data(bio_tagged_syntetic_data, FULL_PATH + big_tagged_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KNTlD9TxRjs0"
      },
      "id": "KNTlD9TxRjs0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "hf_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}